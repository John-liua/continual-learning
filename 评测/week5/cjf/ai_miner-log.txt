=> merge config from utils/user_4splitDomains.yaml
=> merge config from ../official_eva/configs/4splitDomains.yaml
[2023-10-04 05:46:10 4splitDomains](iBatchLearn.py 230): INFO Full config saved to outputs/4splitDomains/trainer_miner-Miner-2023-10-04-05:46:07/config.json
[2023-10-04 05:46:10 4splitDomains](iBatchLearn.py 232): INFO AGENT:
  FIX_BN: false
  FIX_HEAD: true
  MODEL_NAME: resnet50
  MODEL_TYPE: resnet
  NAME: Miner
  REG_COEF: 0.1
  SPARSITY: 0.5
  TYPE: trainer_miner
DATASET:
  BATCHSIZE: 128
  NAME: 4splitDomains
  NUM_CLASSES: 60
  NUM_TASKS: 4
  NUM_WORKERS: 0
  ROOT: input/contest_data/4splitDomains
DOMAIN_INCR: true
GPUID:
- 0
LOGGER_PATH: outputs/4splitDomains/trainer_miner-Miner-2023-10-04-05:46:07
OPT:
  GAMMA: 0.1
  LR: 0.01
  MOMENTUM: 0.9
  NAME: SGD
  SCHEDULE:
  - 50
  SGP_EPS: 0.97
  SGP_EPSINC: 0.0075
  SGP_SCALE: 10
  WEIGHT_DECAY: 0.0
PRINT_FREQ: 10
SEED: 0

[2023-10-04 05:46:10 4splitDomains](iBatchLearn.py 233): INFO {"cfg": "../official_eva/configs/4splitDomains.yaml", "user_cfg": "utils/user_4splitDomains.yaml", "test": true, "task_count": 0, "init_path": "input/init_models/4splitDomains.pth", "ckpt_path": "model_info/4splitDomains/checkpoint-0.pth", "save_ckpt_path": null, "storage_path": "model_info/4splitDomains/storage-0.pth", "save_storage_path": null, "dest_path": "outputs/2023-10-04-05:46:07/prediction_0.pkl", "suffix": "2023-10-04-05:46:07", "distributed": false, "is_main_process": true}
[2023-10-04 05:46:10 4splitDomains](trainer_miner.py 104): INFO => Load model weights: model_info/4splitDomains/checkpoint-0.pth
[2023-10-04 05:46:10 4splitDomains](trainer_miner.py 111): INFO => Load Done
[2023-10-04 05:46:12 4splitDomains](iBatchLearn.py 57): INFO IncreResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (last): ModuleDict(
    (All): Linear(in_features=2048, out_features=60, bias=False)
  )
)
[2023-10-04 05:46:12 4splitDomains](iBatchLearn.py 58): INFO #parameter of model:23630972
[2023-10-04 05:46:12 4splitDomains](iBatchLearn.py 167): INFO test split name:0
[2023-10-04 05:46:13 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:46:13 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 0
[2023-10-04 05:46:17 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:46:17 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 0
[2023-10-04 05:46:18 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:46:19 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 0
[2023-10-04 05:46:20 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:46:21 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 0
[2023-10-04 05:46:23 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:46:23 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 0
[2023-10-04 05:46:25 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:46:25 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 0
[2023-10-04 05:46:26 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:46:26 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 0
--------------------------------Official Evaluation--------------------------------
0 83.20610687022901
=> merge config from utils/user_4splitDomains.yaml
=> merge config from ../official_eva/configs/4splitDomains.yaml
[2023-10-04 05:46:30 4splitDomains](iBatchLearn.py 230): INFO Full config saved to outputs/4splitDomains/trainer_miner-Miner-2023-10-04-05:46:07/config.json
[2023-10-04 05:46:30 4splitDomains](iBatchLearn.py 232): INFO AGENT:
  FIX_BN: false
  FIX_HEAD: true
  MODEL_NAME: resnet50
  MODEL_TYPE: resnet
  NAME: Miner
  REG_COEF: 0.1
  SPARSITY: 0.5
  TYPE: trainer_miner
DATASET:
  BATCHSIZE: 128
  NAME: 4splitDomains
  NUM_CLASSES: 60
  NUM_TASKS: 4
  NUM_WORKERS: 0
  ROOT: input/contest_data/4splitDomains
DOMAIN_INCR: true
GPUID:
- 0
LOGGER_PATH: outputs/4splitDomains/trainer_miner-Miner-2023-10-04-05:46:07
OPT:
  GAMMA: 0.1
  LR: 0.01
  MOMENTUM: 0.9
  NAME: SGD
  SCHEDULE:
  - 50
  SGP_EPS: 0.97
  SGP_EPSINC: 0.0075
  SGP_SCALE: 10
  WEIGHT_DECAY: 0.0
PRINT_FREQ: 10
SEED: 0

[2023-10-04 05:46:30 4splitDomains](iBatchLearn.py 233): INFO {"cfg": "../official_eva/configs/4splitDomains.yaml", "user_cfg": "utils/user_4splitDomains.yaml", "test": true, "task_count": 1, "init_path": "input/init_models/4splitDomains.pth", "ckpt_path": "model_info/4splitDomains/checkpoint-1.pth", "save_ckpt_path": null, "storage_path": "model_info/4splitDomains/storage-1.pth", "save_storage_path": null, "dest_path": "outputs/2023-10-04-05:46:07/prediction_1.pkl", "suffix": "2023-10-04-05:46:07", "distributed": false, "is_main_process": true}
[2023-10-04 05:46:31 4splitDomains](trainer_miner.py 104): INFO => Load model weights: model_info/4splitDomains/checkpoint-1.pth
[2023-10-04 05:46:31 4splitDomains](trainer_miner.py 111): INFO => Load Done
[2023-10-04 05:46:33 4splitDomains](iBatchLearn.py 57): INFO IncreResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (last): ModuleDict(
    (All): Linear(in_features=2048, out_features=60, bias=False)
  )
)
[2023-10-04 05:46:33 4splitDomains](iBatchLearn.py 58): INFO #parameter of model:23630972
[2023-10-04 05:46:33 4splitDomains](iBatchLearn.py 167): INFO test split name:0
[2023-10-04 05:46:34 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:46:34 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 0
[2023-10-04 05:46:38 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:46:38 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 0
[2023-10-04 05:46:39 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:46:39 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 0
[2023-10-04 05:46:41 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:46:41 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 0
[2023-10-04 05:46:43 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:46:43 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 0
[2023-10-04 05:46:45 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:46:45 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 0
[2023-10-04 05:46:46 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:46:46 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 0
[2023-10-04 05:46:46 4splitDomains](iBatchLearn.py 167): INFO test split name:1
[2023-10-04 05:46:47 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:46:48 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 1
[2023-10-04 05:46:49 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:46:49 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 1
[2023-10-04 05:46:51 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:46:51 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 1
[2023-10-04 05:46:53 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:46:53 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 1
[2023-10-04 05:46:55 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:46:55 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 1
[2023-10-04 05:46:57 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:46:57 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 1
[2023-10-04 05:46:58 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:46:58 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 1
--------------------------------Official Evaluation--------------------------------
1 78.12923478888206
=> merge config from utils/user_4splitDomains.yaml
=> merge config from ../official_eva/configs/4splitDomains.yaml
[2023-10-04 05:47:03 4splitDomains](iBatchLearn.py 230): INFO Full config saved to outputs/4splitDomains/trainer_miner-Miner-2023-10-04-05:46:07/config.json
[2023-10-04 05:47:03 4splitDomains](iBatchLearn.py 232): INFO AGENT:
  FIX_BN: false
  FIX_HEAD: true
  MODEL_NAME: resnet50
  MODEL_TYPE: resnet
  NAME: Miner
  REG_COEF: 0.1
  SPARSITY: 0.5
  TYPE: trainer_miner
DATASET:
  BATCHSIZE: 128
  NAME: 4splitDomains
  NUM_CLASSES: 60
  NUM_TASKS: 4
  NUM_WORKERS: 0
  ROOT: input/contest_data/4splitDomains
DOMAIN_INCR: true
GPUID:
- 0
LOGGER_PATH: outputs/4splitDomains/trainer_miner-Miner-2023-10-04-05:46:07
OPT:
  GAMMA: 0.1
  LR: 0.01
  MOMENTUM: 0.9
  NAME: SGD
  SCHEDULE:
  - 50
  SGP_EPS: 0.97
  SGP_EPSINC: 0.0075
  SGP_SCALE: 10
  WEIGHT_DECAY: 0.0
PRINT_FREQ: 10
SEED: 0

[2023-10-04 05:47:03 4splitDomains](iBatchLearn.py 233): INFO {"cfg": "../official_eva/configs/4splitDomains.yaml", "user_cfg": "utils/user_4splitDomains.yaml", "test": true, "task_count": 2, "init_path": "input/init_models/4splitDomains.pth", "ckpt_path": "model_info/4splitDomains/checkpoint-2.pth", "save_ckpt_path": null, "storage_path": "model_info/4splitDomains/storage-2.pth", "save_storage_path": null, "dest_path": "outputs/2023-10-04-05:46:07/prediction_2.pkl", "suffix": "2023-10-04-05:46:07", "distributed": false, "is_main_process": true}
[2023-10-04 05:47:03 4splitDomains](trainer_miner.py 104): INFO => Load model weights: model_info/4splitDomains/checkpoint-2.pth
[2023-10-04 05:47:04 4splitDomains](trainer_miner.py 111): INFO => Load Done
[2023-10-04 05:47:05 4splitDomains](iBatchLearn.py 57): INFO IncreResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (last): ModuleDict(
    (All): Linear(in_features=2048, out_features=60, bias=False)
  )
)
[2023-10-04 05:47:05 4splitDomains](iBatchLearn.py 58): INFO #parameter of model:23630972
[2023-10-04 05:47:05 4splitDomains](iBatchLearn.py 167): INFO test split name:0
[2023-10-04 05:47:06 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:47:06 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 0
[2023-10-04 05:47:10 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:47:10 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 0
[2023-10-04 05:47:12 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:47:12 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 0
[2023-10-04 05:47:14 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:47:14 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 0
[2023-10-04 05:47:15 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:47:16 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 0
[2023-10-04 05:47:17 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:47:17 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 0
[2023-10-04 05:47:18 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:47:18 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 2
[2023-10-04 05:47:19 4splitDomains](iBatchLearn.py 167): INFO test split name:1
[2023-10-04 05:47:20 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:47:20 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 1
[2023-10-04 05:47:22 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:47:22 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 1
[2023-10-04 05:47:24 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:47:24 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 1
[2023-10-04 05:47:25 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:47:26 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 1
[2023-10-04 05:47:27 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:47:27 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 1
[2023-10-04 05:47:29 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:47:29 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 1
[2023-10-04 05:47:30 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:47:30 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 1
[2023-10-04 05:47:31 4splitDomains](iBatchLearn.py 167): INFO test split name:2
[2023-10-04 05:47:34 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:47:35 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 2
[2023-10-04 05:47:39 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:47:39 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 2
[2023-10-04 05:47:44 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:47:44 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 2
[2023-10-04 05:47:49 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:47:49 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 2
[2023-10-04 05:47:53 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:47:53 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 2
[2023-10-04 05:47:57 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:47:58 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 2
[2023-10-04 05:47:59 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:47:59 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 2
--------------------------------Official Evaluation--------------------------------
2 77.42446325735787
=> merge config from utils/user_4splitDomains.yaml
=> merge config from ../official_eva/configs/4splitDomains.yaml
[2023-10-04 05:48:03 4splitDomains](iBatchLearn.py 230): INFO Full config saved to outputs/4splitDomains/trainer_miner-Miner-2023-10-04-05:46:07/config.json
[2023-10-04 05:48:03 4splitDomains](iBatchLearn.py 232): INFO AGENT:
  FIX_BN: false
  FIX_HEAD: true
  MODEL_NAME: resnet50
  MODEL_TYPE: resnet
  NAME: Miner
  REG_COEF: 0.1
  SPARSITY: 0.5
  TYPE: trainer_miner
DATASET:
  BATCHSIZE: 128
  NAME: 4splitDomains
  NUM_CLASSES: 60
  NUM_TASKS: 4
  NUM_WORKERS: 0
  ROOT: input/contest_data/4splitDomains
DOMAIN_INCR: true
GPUID:
- 0
LOGGER_PATH: outputs/4splitDomains/trainer_miner-Miner-2023-10-04-05:46:07
OPT:
  GAMMA: 0.1
  LR: 0.01
  MOMENTUM: 0.9
  NAME: SGD
  SCHEDULE:
  - 50
  SGP_EPS: 0.97
  SGP_EPSINC: 0.0075
  SGP_SCALE: 10
  WEIGHT_DECAY: 0.0
PRINT_FREQ: 10
SEED: 0

[2023-10-04 05:48:03 4splitDomains](iBatchLearn.py 233): INFO {"cfg": "../official_eva/configs/4splitDomains.yaml", "user_cfg": "utils/user_4splitDomains.yaml", "test": true, "task_count": 3, "init_path": "input/init_models/4splitDomains.pth", "ckpt_path": "model_info/4splitDomains/checkpoint-3.pth", "save_ckpt_path": null, "storage_path": "model_info/4splitDomains/storage-3.pth", "save_storage_path": null, "dest_path": "outputs/2023-10-04-05:46:07/prediction_3.pkl", "suffix": "2023-10-04-05:46:07", "distributed": false, "is_main_process": true}
[2023-10-04 05:48:04 4splitDomains](trainer_miner.py 104): INFO => Load model weights: model_info/4splitDomains/checkpoint-3.pth
[2023-10-04 05:48:04 4splitDomains](trainer_miner.py 111): INFO => Load Done
[2023-10-04 05:48:06 4splitDomains](iBatchLearn.py 57): INFO IncreResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (last): ModuleDict(
    (All): Linear(in_features=2048, out_features=60, bias=False)
  )
)
[2023-10-04 05:48:06 4splitDomains](iBatchLearn.py 58): INFO #parameter of model:23630972
[2023-10-04 05:48:06 4splitDomains](iBatchLearn.py 167): INFO test split name:0
[2023-10-04 05:48:07 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:48:07 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 0
[2023-10-04 05:48:10 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:48:11 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 0
[2023-10-04 05:48:12 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:48:12 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 0
[2023-10-04 05:48:14 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:48:14 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 0
[2023-10-04 05:48:16 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:48:16 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 0
[2023-10-04 05:48:18 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:48:18 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 0
[2023-10-04 05:48:19 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:48:19 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 2
[2023-10-04 05:48:19 4splitDomains](iBatchLearn.py 167): INFO test split name:1
[2023-10-04 05:48:20 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:48:20 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 1
[2023-10-04 05:48:22 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:48:22 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 1
[2023-10-04 05:48:24 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:48:25 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 1
[2023-10-04 05:48:27 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:48:27 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 1
[2023-10-04 05:48:29 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:48:29 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 1
[2023-10-04 05:48:30 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:48:31 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 1
[2023-10-04 05:48:31 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:48:32 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 1
[2023-10-04 05:48:32 4splitDomains](iBatchLearn.py 167): INFO test split name:2
[2023-10-04 05:48:36 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:48:37 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 3
[2023-10-04 05:48:41 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:48:41 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 2
[2023-10-04 05:48:46 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:48:46 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 2
[2023-10-04 05:48:51 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:48:51 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 2
[2023-10-04 05:48:55 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:48:56 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 2
[2023-10-04 05:49:00 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:49:01 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 2
[2023-10-04 05:49:02 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:49:02 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 2
[2023-10-04 05:49:03 4splitDomains](iBatchLearn.py 167): INFO test split name:3
[2023-10-04 05:49:04 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:49:04 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 3
[2023-10-04 05:49:07 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:49:07 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 3
[2023-10-04 05:49:09 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:49:10 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 3
[2023-10-04 05:49:11 4splitDomains](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:49:11 4splitDomains](trainer_miner.py 780): INFO done
infered task id is 3
--------------------------------Official Evaluation--------------------------------
3 76.53838496839944
=> merge config from utils/user_10splitTasks.yaml
=> merge config from ../official_eva/configs/10splitTasks.yaml
[2023-10-04 05:49:16 10splitTasks](iBatchLearn.py 230): INFO Full config saved to outputs/10splitTasks/trainer_miner-Miner-2023-10-04-05:46:07/config.json
[2023-10-04 05:49:16 10splitTasks](iBatchLearn.py 232): INFO AGENT:
  FIX_BN: false
  FIX_HEAD: true
  MODEL_NAME: resnet50
  MODEL_TYPE: resnet
  NAME: Miner
  REG_COEF: 0.1
  SPARSITY: 0.5
  TYPE: trainer_miner
DATASET:
  BATCHSIZE: 128
  NAME: 10splitTasks
  NUM_CLASSES: 100
  NUM_TASKS: 10
  NUM_WORKERS: 0
  ROOT: input/contest_data/10splitTasks
DOMAIN_INCR: false
GPUID:
- 0
LOGGER_PATH: outputs/10splitTasks/trainer_miner-Miner-2023-10-04-05:46:07
OPT:
  GAMMA: 0.1
  LR: 0.01
  MOMENTUM: 0.9
  NAME: SGD
  SCHEDULE:
  - 80
  SGP_EPS: 0.97
  SGP_EPSINC: 0.0075
  SGP_SCALE: 10
  WEIGHT_DECAY: 0.0
PRINT_FREQ: 10
SEED: 0

[2023-10-04 05:49:16 10splitTasks](iBatchLearn.py 233): INFO {"cfg": "../official_eva/configs/10splitTasks.yaml", "user_cfg": "utils/user_10splitTasks.yaml", "test": true, "task_count": 0, "init_path": "input/init_models/10splitTasks.pth", "ckpt_path": "model_info/10splitTasks/checkpoint-0.pth", "save_ckpt_path": null, "storage_path": "model_info/10splitTasks/storage-0.pth", "save_storage_path": null, "dest_path": "outputs/2023-10-04-05:46:07/prediction_0.pkl", "suffix": "2023-10-04-05:46:07", "distributed": false, "is_main_process": true}
[2023-10-04 05:49:16 10splitTasks](trainer_miner.py 104): INFO => Load model weights: model_info/10splitTasks/checkpoint-0.pth
[2023-10-04 05:49:16 10splitTasks](trainer_miner.py 111): INFO => Load Done
[2023-10-04 05:49:18 10splitTasks](iBatchLearn.py 57): INFO IncreResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (last): ModuleDict(
    (0): Linear(in_features=2048, out_features=10, bias=False)
    (1): Linear(in_features=2048, out_features=10, bias=False)
    (2): Linear(in_features=2048, out_features=10, bias=False)
    (3): Linear(in_features=2048, out_features=10, bias=False)
    (4): Linear(in_features=2048, out_features=10, bias=False)
    (5): Linear(in_features=2048, out_features=10, bias=False)
    (6): Linear(in_features=2048, out_features=10, bias=False)
    (7): Linear(in_features=2048, out_features=10, bias=False)
    (8): Linear(in_features=2048, out_features=10, bias=False)
    (9): Linear(in_features=2048, out_features=10, bias=False)
  )
)
[2023-10-04 05:49:18 10splitTasks](iBatchLearn.py 58): INFO #parameter of model:23712832
[2023-10-04 05:49:18 10splitTasks](iBatchLearn.py 167): INFO test split name:0
[2023-10-04 05:49:20 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:49:20 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:49:23 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:49:23 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:49:25 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:49:25 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:49:27 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:49:27 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:49:28 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:49:28 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:49:29 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:49:30 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:49:31 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:49:31 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:49:32 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:49:32 10splitTasks](trainer_miner.py 780): INFO done
--------------------------------Official Evaluation--------------------------------
0 76.6
=> merge config from utils/user_10splitTasks.yaml
=> merge config from ../official_eva/configs/10splitTasks.yaml
[2023-10-04 05:49:36 10splitTasks](iBatchLearn.py 230): INFO Full config saved to outputs/10splitTasks/trainer_miner-Miner-2023-10-04-05:46:07/config.json
[2023-10-04 05:49:36 10splitTasks](iBatchLearn.py 232): INFO AGENT:
  FIX_BN: false
  FIX_HEAD: true
  MODEL_NAME: resnet50
  MODEL_TYPE: resnet
  NAME: Miner
  REG_COEF: 0.1
  SPARSITY: 0.5
  TYPE: trainer_miner
DATASET:
  BATCHSIZE: 128
  NAME: 10splitTasks
  NUM_CLASSES: 100
  NUM_TASKS: 10
  NUM_WORKERS: 0
  ROOT: input/contest_data/10splitTasks
DOMAIN_INCR: false
GPUID:
- 0
LOGGER_PATH: outputs/10splitTasks/trainer_miner-Miner-2023-10-04-05:46:07
OPT:
  GAMMA: 0.1
  LR: 0.01
  MOMENTUM: 0.9
  NAME: SGD
  SCHEDULE:
  - 80
  SGP_EPS: 0.97
  SGP_EPSINC: 0.0075
  SGP_SCALE: 10
  WEIGHT_DECAY: 0.0
PRINT_FREQ: 10
SEED: 0

[2023-10-04 05:49:36 10splitTasks](iBatchLearn.py 233): INFO {"cfg": "../official_eva/configs/10splitTasks.yaml", "user_cfg": "utils/user_10splitTasks.yaml", "test": true, "task_count": 1, "init_path": "input/init_models/10splitTasks.pth", "ckpt_path": "model_info/10splitTasks/checkpoint-1.pth", "save_ckpt_path": null, "storage_path": "model_info/10splitTasks/storage-1.pth", "save_storage_path": null, "dest_path": "outputs/2023-10-04-05:46:07/prediction_1.pkl", "suffix": "2023-10-04-05:46:07", "distributed": false, "is_main_process": true}
[2023-10-04 05:49:36 10splitTasks](trainer_miner.py 104): INFO => Load model weights: model_info/10splitTasks/checkpoint-1.pth
[2023-10-04 05:49:37 10splitTasks](trainer_miner.py 111): INFO => Load Done
[2023-10-04 05:49:38 10splitTasks](iBatchLearn.py 57): INFO IncreResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (last): ModuleDict(
    (0): Linear(in_features=2048, out_features=10, bias=False)
    (1): Linear(in_features=2048, out_features=10, bias=False)
    (2): Linear(in_features=2048, out_features=10, bias=False)
    (3): Linear(in_features=2048, out_features=10, bias=False)
    (4): Linear(in_features=2048, out_features=10, bias=False)
    (5): Linear(in_features=2048, out_features=10, bias=False)
    (6): Linear(in_features=2048, out_features=10, bias=False)
    (7): Linear(in_features=2048, out_features=10, bias=False)
    (8): Linear(in_features=2048, out_features=10, bias=False)
    (9): Linear(in_features=2048, out_features=10, bias=False)
  )
)
[2023-10-04 05:49:38 10splitTasks](iBatchLearn.py 58): INFO #parameter of model:23712832
[2023-10-04 05:49:38 10splitTasks](iBatchLearn.py 167): INFO test split name:0
[2023-10-04 05:49:40 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:49:40 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:49:43 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:49:43 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:49:44 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:49:45 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:49:46 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:49:46 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:49:47 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:49:47 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:49:49 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:49:49 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:49:50 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:49:50 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:49:51 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:49:51 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:49:51 10splitTasks](iBatchLearn.py 167): INFO test split name:1
[2023-10-04 05:49:52 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:49:53 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:49:55 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:49:55 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:49:56 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:49:56 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:49:57 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:49:58 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:49:59 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:49:59 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:50:00 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:50:01 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:50:02 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:50:02 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:50:03 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:50:03 10splitTasks](trainer_miner.py 780): INFO done
--------------------------------Official Evaluation--------------------------------
1 73.94999999999999
=> merge config from utils/user_10splitTasks.yaml
=> merge config from ../official_eva/configs/10splitTasks.yaml
[2023-10-04 05:50:08 10splitTasks](iBatchLearn.py 230): INFO Full config saved to outputs/10splitTasks/trainer_miner-Miner-2023-10-04-05:46:07/config.json
[2023-10-04 05:50:08 10splitTasks](iBatchLearn.py 232): INFO AGENT:
  FIX_BN: false
  FIX_HEAD: true
  MODEL_NAME: resnet50
  MODEL_TYPE: resnet
  NAME: Miner
  REG_COEF: 0.1
  SPARSITY: 0.5
  TYPE: trainer_miner
DATASET:
  BATCHSIZE: 128
  NAME: 10splitTasks
  NUM_CLASSES: 100
  NUM_TASKS: 10
  NUM_WORKERS: 0
  ROOT: input/contest_data/10splitTasks
DOMAIN_INCR: false
GPUID:
- 0
LOGGER_PATH: outputs/10splitTasks/trainer_miner-Miner-2023-10-04-05:46:07
OPT:
  GAMMA: 0.1
  LR: 0.01
  MOMENTUM: 0.9
  NAME: SGD
  SCHEDULE:
  - 80
  SGP_EPS: 0.97
  SGP_EPSINC: 0.0075
  SGP_SCALE: 10
  WEIGHT_DECAY: 0.0
PRINT_FREQ: 10
SEED: 0

[2023-10-04 05:50:08 10splitTasks](iBatchLearn.py 233): INFO {"cfg": "../official_eva/configs/10splitTasks.yaml", "user_cfg": "utils/user_10splitTasks.yaml", "test": true, "task_count": 2, "init_path": "input/init_models/10splitTasks.pth", "ckpt_path": "model_info/10splitTasks/checkpoint-2.pth", "save_ckpt_path": null, "storage_path": "model_info/10splitTasks/storage-2.pth", "save_storage_path": null, "dest_path": "outputs/2023-10-04-05:46:07/prediction_2.pkl", "suffix": "2023-10-04-05:46:07", "distributed": false, "is_main_process": true}
[2023-10-04 05:50:08 10splitTasks](trainer_miner.py 104): INFO => Load model weights: model_info/10splitTasks/checkpoint-2.pth
[2023-10-04 05:50:09 10splitTasks](trainer_miner.py 111): INFO => Load Done
[2023-10-04 05:50:11 10splitTasks](iBatchLearn.py 57): INFO IncreResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (last): ModuleDict(
    (0): Linear(in_features=2048, out_features=10, bias=False)
    (1): Linear(in_features=2048, out_features=10, bias=False)
    (2): Linear(in_features=2048, out_features=10, bias=False)
    (3): Linear(in_features=2048, out_features=10, bias=False)
    (4): Linear(in_features=2048, out_features=10, bias=False)
    (5): Linear(in_features=2048, out_features=10, bias=False)
    (6): Linear(in_features=2048, out_features=10, bias=False)
    (7): Linear(in_features=2048, out_features=10, bias=False)
    (8): Linear(in_features=2048, out_features=10, bias=False)
    (9): Linear(in_features=2048, out_features=10, bias=False)
  )
)
[2023-10-04 05:50:11 10splitTasks](iBatchLearn.py 58): INFO #parameter of model:23712832
[2023-10-04 05:50:11 10splitTasks](iBatchLearn.py 167): INFO test split name:0
[2023-10-04 05:50:12 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:50:12 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:50:16 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:50:16 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:50:18 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:50:18 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:50:20 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:50:20 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:50:22 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:50:22 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:50:24 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:50:24 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:50:26 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:50:26 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:50:28 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:50:28 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:50:28 10splitTasks](iBatchLearn.py 167): INFO test split name:1
[2023-10-04 05:50:30 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:50:30 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:50:31 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:50:32 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:50:33 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:50:33 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:50:34 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:50:35 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:50:36 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:50:36 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:50:37 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:50:38 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:50:39 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:50:39 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:50:40 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:50:40 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:50:40 10splitTasks](iBatchLearn.py 167): INFO test split name:2
[2023-10-04 05:50:42 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:50:43 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:50:45 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:50:45 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:50:46 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:50:46 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:50:48 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:50:49 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:50:51 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:50:51 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:50:53 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:50:53 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:50:55 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:50:55 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:50:56 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:50:57 10splitTasks](trainer_miner.py 780): INFO done
--------------------------------Official Evaluation--------------------------------
2 74.19999999999999
=> merge config from utils/user_10splitTasks.yaml
=> merge config from ../official_eva/configs/10splitTasks.yaml
[2023-10-04 05:51:01 10splitTasks](iBatchLearn.py 230): INFO Full config saved to outputs/10splitTasks/trainer_miner-Miner-2023-10-04-05:46:07/config.json
[2023-10-04 05:51:01 10splitTasks](iBatchLearn.py 232): INFO AGENT:
  FIX_BN: false
  FIX_HEAD: true
  MODEL_NAME: resnet50
  MODEL_TYPE: resnet
  NAME: Miner
  REG_COEF: 0.1
  SPARSITY: 0.5
  TYPE: trainer_miner
DATASET:
  BATCHSIZE: 128
  NAME: 10splitTasks
  NUM_CLASSES: 100
  NUM_TASKS: 10
  NUM_WORKERS: 0
  ROOT: input/contest_data/10splitTasks
DOMAIN_INCR: false
GPUID:
- 0
LOGGER_PATH: outputs/10splitTasks/trainer_miner-Miner-2023-10-04-05:46:07
OPT:
  GAMMA: 0.1
  LR: 0.01
  MOMENTUM: 0.9
  NAME: SGD
  SCHEDULE:
  - 80
  SGP_EPS: 0.97
  SGP_EPSINC: 0.0075
  SGP_SCALE: 10
  WEIGHT_DECAY: 0.0
PRINT_FREQ: 10
SEED: 0

[2023-10-04 05:51:01 10splitTasks](iBatchLearn.py 233): INFO {"cfg": "../official_eva/configs/10splitTasks.yaml", "user_cfg": "utils/user_10splitTasks.yaml", "test": true, "task_count": 3, "init_path": "input/init_models/10splitTasks.pth", "ckpt_path": "model_info/10splitTasks/checkpoint-3.pth", "save_ckpt_path": null, "storage_path": "model_info/10splitTasks/storage-3.pth", "save_storage_path": null, "dest_path": "outputs/2023-10-04-05:46:07/prediction_3.pkl", "suffix": "2023-10-04-05:46:07", "distributed": false, "is_main_process": true}
[2023-10-04 05:51:01 10splitTasks](trainer_miner.py 104): INFO => Load model weights: model_info/10splitTasks/checkpoint-3.pth
[2023-10-04 05:51:02 10splitTasks](trainer_miner.py 111): INFO => Load Done
[2023-10-04 05:51:04 10splitTasks](iBatchLearn.py 57): INFO IncreResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (last): ModuleDict(
    (0): Linear(in_features=2048, out_features=10, bias=False)
    (1): Linear(in_features=2048, out_features=10, bias=False)
    (2): Linear(in_features=2048, out_features=10, bias=False)
    (3): Linear(in_features=2048, out_features=10, bias=False)
    (4): Linear(in_features=2048, out_features=10, bias=False)
    (5): Linear(in_features=2048, out_features=10, bias=False)
    (6): Linear(in_features=2048, out_features=10, bias=False)
    (7): Linear(in_features=2048, out_features=10, bias=False)
    (8): Linear(in_features=2048, out_features=10, bias=False)
    (9): Linear(in_features=2048, out_features=10, bias=False)
  )
)
[2023-10-04 05:51:04 10splitTasks](iBatchLearn.py 58): INFO #parameter of model:23712832
[2023-10-04 05:51:04 10splitTasks](iBatchLearn.py 167): INFO test split name:0
[2023-10-04 05:51:05 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:51:06 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:51:09 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:51:09 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:51:11 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:51:11 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:51:13 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:51:13 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:51:15 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:51:15 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:51:16 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:51:16 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:51:18 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:51:18 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:51:20 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:51:20 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:51:20 10splitTasks](iBatchLearn.py 167): INFO test split name:1
[2023-10-04 05:51:21 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:51:22 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:51:23 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:51:23 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:51:24 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:51:24 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:51:26 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:51:26 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:51:27 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:51:28 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:51:29 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:51:29 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:51:30 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:51:31 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:51:32 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:51:32 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:51:32 10splitTasks](iBatchLearn.py 167): INFO test split name:2
[2023-10-04 05:51:33 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:51:34 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:51:35 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:51:35 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:51:36 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:51:36 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:51:38 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:51:38 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:51:39 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:51:40 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:51:41 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:51:41 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:51:42 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:51:43 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:51:44 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:51:44 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:51:44 10splitTasks](iBatchLearn.py 167): INFO test split name:3
[2023-10-04 05:51:45 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:51:47 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:51:48 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:51:49 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:51:51 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:51:51 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:51:53 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:51:54 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:51:55 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:51:55 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:51:57 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:51:58 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:51:59 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:52:00 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:52:01 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:52:01 10splitTasks](trainer_miner.py 780): INFO done
--------------------------------Official Evaluation--------------------------------
3 73.82499999999999
=> merge config from utils/user_10splitTasks.yaml
=> merge config from ../official_eva/configs/10splitTasks.yaml
[2023-10-04 05:52:06 10splitTasks](iBatchLearn.py 230): INFO Full config saved to outputs/10splitTasks/trainer_miner-Miner-2023-10-04-05:46:07/config.json
[2023-10-04 05:52:06 10splitTasks](iBatchLearn.py 232): INFO AGENT:
  FIX_BN: false
  FIX_HEAD: true
  MODEL_NAME: resnet50
  MODEL_TYPE: resnet
  NAME: Miner
  REG_COEF: 0.1
  SPARSITY: 0.5
  TYPE: trainer_miner
DATASET:
  BATCHSIZE: 128
  NAME: 10splitTasks
  NUM_CLASSES: 100
  NUM_TASKS: 10
  NUM_WORKERS: 0
  ROOT: input/contest_data/10splitTasks
DOMAIN_INCR: false
GPUID:
- 0
LOGGER_PATH: outputs/10splitTasks/trainer_miner-Miner-2023-10-04-05:46:07
OPT:
  GAMMA: 0.1
  LR: 0.01
  MOMENTUM: 0.9
  NAME: SGD
  SCHEDULE:
  - 80
  SGP_EPS: 0.97
  SGP_EPSINC: 0.0075
  SGP_SCALE: 10
  WEIGHT_DECAY: 0.0
PRINT_FREQ: 10
SEED: 0

[2023-10-04 05:52:06 10splitTasks](iBatchLearn.py 233): INFO {"cfg": "../official_eva/configs/10splitTasks.yaml", "user_cfg": "utils/user_10splitTasks.yaml", "test": true, "task_count": 4, "init_path": "input/init_models/10splitTasks.pth", "ckpt_path": "model_info/10splitTasks/checkpoint-4.pth", "save_ckpt_path": null, "storage_path": "model_info/10splitTasks/storage-4.pth", "save_storage_path": null, "dest_path": "outputs/2023-10-04-05:46:07/prediction_4.pkl", "suffix": "2023-10-04-05:46:07", "distributed": false, "is_main_process": true}
[2023-10-04 05:52:06 10splitTasks](trainer_miner.py 104): INFO => Load model weights: model_info/10splitTasks/checkpoint-4.pth
[2023-10-04 05:52:07 10splitTasks](trainer_miner.py 111): INFO => Load Done
[2023-10-04 05:52:09 10splitTasks](iBatchLearn.py 57): INFO IncreResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (last): ModuleDict(
    (0): Linear(in_features=2048, out_features=10, bias=False)
    (1): Linear(in_features=2048, out_features=10, bias=False)
    (2): Linear(in_features=2048, out_features=10, bias=False)
    (3): Linear(in_features=2048, out_features=10, bias=False)
    (4): Linear(in_features=2048, out_features=10, bias=False)
    (5): Linear(in_features=2048, out_features=10, bias=False)
    (6): Linear(in_features=2048, out_features=10, bias=False)
    (7): Linear(in_features=2048, out_features=10, bias=False)
    (8): Linear(in_features=2048, out_features=10, bias=False)
    (9): Linear(in_features=2048, out_features=10, bias=False)
  )
)
[2023-10-04 05:52:09 10splitTasks](iBatchLearn.py 58): INFO #parameter of model:23712832
[2023-10-04 05:52:09 10splitTasks](iBatchLearn.py 167): INFO test split name:0
[2023-10-04 05:52:10 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:52:10 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:52:14 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:52:14 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:52:15 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:52:15 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:52:16 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:52:17 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:52:18 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:52:18 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:52:19 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:52:19 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:52:21 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:52:21 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:52:22 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:52:22 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:52:22 10splitTasks](iBatchLearn.py 167): INFO test split name:1
[2023-10-04 05:52:23 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:52:23 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:52:25 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:52:25 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:52:26 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:52:26 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:52:27 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:52:28 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:52:29 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:52:29 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:52:31 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:52:31 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:52:33 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:52:34 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:52:35 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:52:35 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:52:36 10splitTasks](iBatchLearn.py 167): INFO test split name:2
[2023-10-04 05:52:37 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:52:38 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:52:40 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:52:40 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:52:41 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:52:42 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:52:43 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:52:43 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:52:44 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:52:45 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:52:46 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:52:46 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:52:47 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:52:48 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:52:49 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:52:49 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:52:49 10splitTasks](iBatchLearn.py 167): INFO test split name:3
[2023-10-04 05:52:50 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:52:50 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:52:52 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:52:52 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:52:53 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:52:54 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:52:55 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:52:55 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:52:57 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:52:57 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:52:58 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:52:58 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:53:00 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:53:00 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:53:02 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:53:02 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:53:02 10splitTasks](iBatchLearn.py 167): INFO test split name:4
[2023-10-04 05:53:04 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:53:06 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:53:07 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:53:08 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:53:09 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:53:10 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:53:11 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:53:11 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:53:13 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:53:13 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:53:14 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:53:14 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:53:16 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:53:16 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:53:17 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:53:18 10splitTasks](trainer_miner.py 780): INFO done
--------------------------------Official Evaluation--------------------------------
4 73.75999999999999
=> merge config from utils/user_10splitTasks.yaml
=> merge config from ../official_eva/configs/10splitTasks.yaml
[2023-10-04 05:53:22 10splitTasks](iBatchLearn.py 230): INFO Full config saved to outputs/10splitTasks/trainer_miner-Miner-2023-10-04-05:46:07/config.json
[2023-10-04 05:53:22 10splitTasks](iBatchLearn.py 232): INFO AGENT:
  FIX_BN: false
  FIX_HEAD: true
  MODEL_NAME: resnet50
  MODEL_TYPE: resnet
  NAME: Miner
  REG_COEF: 0.1
  SPARSITY: 0.5
  TYPE: trainer_miner
DATASET:
  BATCHSIZE: 128
  NAME: 10splitTasks
  NUM_CLASSES: 100
  NUM_TASKS: 10
  NUM_WORKERS: 0
  ROOT: input/contest_data/10splitTasks
DOMAIN_INCR: false
GPUID:
- 0
LOGGER_PATH: outputs/10splitTasks/trainer_miner-Miner-2023-10-04-05:46:07
OPT:
  GAMMA: 0.1
  LR: 0.01
  MOMENTUM: 0.9
  NAME: SGD
  SCHEDULE:
  - 80
  SGP_EPS: 0.97
  SGP_EPSINC: 0.0075
  SGP_SCALE: 10
  WEIGHT_DECAY: 0.0
PRINT_FREQ: 10
SEED: 0

[2023-10-04 05:53:22 10splitTasks](iBatchLearn.py 233): INFO {"cfg": "../official_eva/configs/10splitTasks.yaml", "user_cfg": "utils/user_10splitTasks.yaml", "test": true, "task_count": 5, "init_path": "input/init_models/10splitTasks.pth", "ckpt_path": "model_info/10splitTasks/checkpoint-5.pth", "save_ckpt_path": null, "storage_path": "model_info/10splitTasks/storage-5.pth", "save_storage_path": null, "dest_path": "outputs/2023-10-04-05:46:07/prediction_5.pkl", "suffix": "2023-10-04-05:46:07", "distributed": false, "is_main_process": true}
[2023-10-04 05:53:22 10splitTasks](trainer_miner.py 104): INFO => Load model weights: model_info/10splitTasks/checkpoint-5.pth
[2023-10-04 05:53:24 10splitTasks](trainer_miner.py 111): INFO => Load Done
[2023-10-04 05:53:25 10splitTasks](iBatchLearn.py 57): INFO IncreResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (last): ModuleDict(
    (0): Linear(in_features=2048, out_features=10, bias=False)
    (1): Linear(in_features=2048, out_features=10, bias=False)
    (2): Linear(in_features=2048, out_features=10, bias=False)
    (3): Linear(in_features=2048, out_features=10, bias=False)
    (4): Linear(in_features=2048, out_features=10, bias=False)
    (5): Linear(in_features=2048, out_features=10, bias=False)
    (6): Linear(in_features=2048, out_features=10, bias=False)
    (7): Linear(in_features=2048, out_features=10, bias=False)
    (8): Linear(in_features=2048, out_features=10, bias=False)
    (9): Linear(in_features=2048, out_features=10, bias=False)
  )
)
[2023-10-04 05:53:25 10splitTasks](iBatchLearn.py 58): INFO #parameter of model:23712832
[2023-10-04 05:53:25 10splitTasks](iBatchLearn.py 167): INFO test split name:0
[2023-10-04 05:53:27 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:53:27 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:53:30 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:53:30 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:53:32 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:53:32 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:53:33 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:53:33 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:53:34 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:53:35 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:53:36 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:53:36 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:53:37 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:53:37 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:53:38 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:53:39 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:53:39 10splitTasks](iBatchLearn.py 167): INFO test split name:1
[2023-10-04 05:53:40 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:53:40 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:53:41 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:53:42 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:53:43 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:53:43 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:53:44 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:53:44 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:53:46 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:53:46 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:53:47 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:53:47 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:53:49 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:53:49 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:53:50 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:53:50 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:53:50 10splitTasks](iBatchLearn.py 167): INFO test split name:2
[2023-10-04 05:53:51 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:53:52 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:53:53 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:53:53 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:53:54 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:53:55 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:53:56 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:53:56 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:53:57 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:53:57 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:53:59 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:53:59 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:54:00 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:54:00 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:54:02 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:54:02 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:54:02 10splitTasks](iBatchLearn.py 167): INFO test split name:3
[2023-10-04 05:54:04 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:54:04 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:54:05 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:54:06 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:54:07 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:54:07 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:54:09 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:54:09 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:54:10 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:54:11 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:54:12 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:54:12 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:54:14 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:54:14 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:54:15 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:54:15 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:54:15 10splitTasks](iBatchLearn.py 167): INFO test split name:4
[2023-10-04 05:54:16 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:54:17 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:54:18 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:54:18 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:54:20 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:54:20 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:54:22 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:54:22 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:54:24 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:54:24 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:54:26 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:54:26 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:54:27 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:54:28 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:54:29 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:54:29 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:54:30 10splitTasks](iBatchLearn.py 167): INFO test split name:5
[2023-10-04 05:54:31 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:54:32 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:54:34 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:54:34 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:54:35 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:54:36 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:54:37 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:54:37 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:54:38 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:54:39 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:54:40 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:54:40 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:54:42 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:54:42 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:54:43 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:54:43 10splitTasks](trainer_miner.py 780): INFO done
--------------------------------Official Evaluation--------------------------------
5 73.19999999999999
=> merge config from utils/user_10splitTasks.yaml
=> merge config from ../official_eva/configs/10splitTasks.yaml
[2023-10-04 05:54:48 10splitTasks](iBatchLearn.py 230): INFO Full config saved to outputs/10splitTasks/trainer_miner-Miner-2023-10-04-05:46:07/config.json
[2023-10-04 05:54:48 10splitTasks](iBatchLearn.py 232): INFO AGENT:
  FIX_BN: false
  FIX_HEAD: true
  MODEL_NAME: resnet50
  MODEL_TYPE: resnet
  NAME: Miner
  REG_COEF: 0.1
  SPARSITY: 0.5
  TYPE: trainer_miner
DATASET:
  BATCHSIZE: 128
  NAME: 10splitTasks
  NUM_CLASSES: 100
  NUM_TASKS: 10
  NUM_WORKERS: 0
  ROOT: input/contest_data/10splitTasks
DOMAIN_INCR: false
GPUID:
- 0
LOGGER_PATH: outputs/10splitTasks/trainer_miner-Miner-2023-10-04-05:46:07
OPT:
  GAMMA: 0.1
  LR: 0.01
  MOMENTUM: 0.9
  NAME: SGD
  SCHEDULE:
  - 80
  SGP_EPS: 0.97
  SGP_EPSINC: 0.0075
  SGP_SCALE: 10
  WEIGHT_DECAY: 0.0
PRINT_FREQ: 10
SEED: 0

[2023-10-04 05:54:48 10splitTasks](iBatchLearn.py 233): INFO {"cfg": "../official_eva/configs/10splitTasks.yaml", "user_cfg": "utils/user_10splitTasks.yaml", "test": true, "task_count": 6, "init_path": "input/init_models/10splitTasks.pth", "ckpt_path": "model_info/10splitTasks/checkpoint-6.pth", "save_ckpt_path": null, "storage_path": "model_info/10splitTasks/storage-6.pth", "save_storage_path": null, "dest_path": "outputs/2023-10-04-05:46:07/prediction_6.pkl", "suffix": "2023-10-04-05:46:07", "distributed": false, "is_main_process": true}
[2023-10-04 05:54:48 10splitTasks](trainer_miner.py 104): INFO => Load model weights: model_info/10splitTasks/checkpoint-6.pth
[2023-10-04 05:54:50 10splitTasks](trainer_miner.py 111): INFO => Load Done
[2023-10-04 05:54:51 10splitTasks](iBatchLearn.py 57): INFO IncreResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (last): ModuleDict(
    (0): Linear(in_features=2048, out_features=10, bias=False)
    (1): Linear(in_features=2048, out_features=10, bias=False)
    (2): Linear(in_features=2048, out_features=10, bias=False)
    (3): Linear(in_features=2048, out_features=10, bias=False)
    (4): Linear(in_features=2048, out_features=10, bias=False)
    (5): Linear(in_features=2048, out_features=10, bias=False)
    (6): Linear(in_features=2048, out_features=10, bias=False)
    (7): Linear(in_features=2048, out_features=10, bias=False)
    (8): Linear(in_features=2048, out_features=10, bias=False)
    (9): Linear(in_features=2048, out_features=10, bias=False)
  )
)
[2023-10-04 05:54:51 10splitTasks](iBatchLearn.py 58): INFO #parameter of model:23712832
[2023-10-04 05:54:51 10splitTasks](iBatchLearn.py 167): INFO test split name:0
[2023-10-04 05:54:53 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:54:53 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:54:57 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:54:57 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:54:58 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:54:58 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:55:00 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:55:00 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:55:01 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:55:01 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:55:03 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:55:03 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:55:05 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:55:05 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:55:07 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:55:07 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:55:07 10splitTasks](iBatchLearn.py 167): INFO test split name:1
[2023-10-04 05:55:08 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:55:08 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:55:10 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:55:10 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:55:11 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:55:11 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:55:13 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:55:13 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:55:14 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:55:14 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:55:16 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:55:16 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:55:17 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:55:17 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:55:18 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:55:19 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:55:19 10splitTasks](iBatchLearn.py 167): INFO test split name:2
[2023-10-04 05:55:20 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:55:20 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:55:21 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:55:22 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:55:23 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:55:23 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:55:24 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:55:25 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:55:26 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:55:26 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:55:27 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:55:28 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:55:29 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:55:29 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:55:30 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:55:30 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:55:31 10splitTasks](iBatchLearn.py 167): INFO test split name:3
[2023-10-04 05:55:32 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:55:32 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:55:34 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:55:34 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:55:36 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:55:36 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:55:38 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:55:39 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:55:40 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:55:41 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:55:43 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:55:43 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:55:45 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:55:45 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:55:47 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:55:47 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:55:47 10splitTasks](iBatchLearn.py 167): INFO test split name:4
[2023-10-04 05:55:49 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:55:49 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:55:51 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:55:51 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:55:53 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:55:54 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:55:56 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:55:56 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:55:58 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:55:58 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:56:00 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:56:00 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:56:02 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:56:02 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:56:04 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:56:04 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:56:04 10splitTasks](iBatchLearn.py 167): INFO test split name:5
[2023-10-04 05:56:06 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:56:07 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:56:08 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:56:09 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:56:11 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:56:11 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:56:13 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:56:13 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:56:15 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:56:16 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:56:17 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:56:18 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:56:20 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:56:20 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:56:22 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:56:22 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:56:22 10splitTasks](iBatchLearn.py 167): INFO test split name:6
[2023-10-04 05:56:24 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:56:26 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:56:27 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:56:27 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:56:29 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:56:29 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:56:30 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:56:31 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:56:32 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:56:32 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:56:33 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:56:34 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:56:36 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:56:36 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:56:38 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:56:38 10splitTasks](trainer_miner.py 780): INFO done
--------------------------------Official Evaluation--------------------------------
6 73.84285714285714
=> merge config from utils/user_10splitTasks.yaml
=> merge config from ../official_eva/configs/10splitTasks.yaml
[2023-10-04 05:56:43 10splitTasks](iBatchLearn.py 230): INFO Full config saved to outputs/10splitTasks/trainer_miner-Miner-2023-10-04-05:46:07/config.json
[2023-10-04 05:56:43 10splitTasks](iBatchLearn.py 232): INFO AGENT:
  FIX_BN: false
  FIX_HEAD: true
  MODEL_NAME: resnet50
  MODEL_TYPE: resnet
  NAME: Miner
  REG_COEF: 0.1
  SPARSITY: 0.5
  TYPE: trainer_miner
DATASET:
  BATCHSIZE: 128
  NAME: 10splitTasks
  NUM_CLASSES: 100
  NUM_TASKS: 10
  NUM_WORKERS: 0
  ROOT: input/contest_data/10splitTasks
DOMAIN_INCR: false
GPUID:
- 0
LOGGER_PATH: outputs/10splitTasks/trainer_miner-Miner-2023-10-04-05:46:07
OPT:
  GAMMA: 0.1
  LR: 0.01
  MOMENTUM: 0.9
  NAME: SGD
  SCHEDULE:
  - 80
  SGP_EPS: 0.97
  SGP_EPSINC: 0.0075
  SGP_SCALE: 10
  WEIGHT_DECAY: 0.0
PRINT_FREQ: 10
SEED: 0

[2023-10-04 05:56:43 10splitTasks](iBatchLearn.py 233): INFO {"cfg": "../official_eva/configs/10splitTasks.yaml", "user_cfg": "utils/user_10splitTasks.yaml", "test": true, "task_count": 7, "init_path": "input/init_models/10splitTasks.pth", "ckpt_path": "model_info/10splitTasks/checkpoint-7.pth", "save_ckpt_path": null, "storage_path": "model_info/10splitTasks/storage-7.pth", "save_storage_path": null, "dest_path": "outputs/2023-10-04-05:46:07/prediction_7.pkl", "suffix": "2023-10-04-05:46:07", "distributed": false, "is_main_process": true}
[2023-10-04 05:56:43 10splitTasks](trainer_miner.py 104): INFO => Load model weights: model_info/10splitTasks/checkpoint-7.pth
[2023-10-04 05:56:44 10splitTasks](trainer_miner.py 111): INFO => Load Done
[2023-10-04 05:56:46 10splitTasks](iBatchLearn.py 57): INFO IncreResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (last): ModuleDict(
    (0): Linear(in_features=2048, out_features=10, bias=False)
    (1): Linear(in_features=2048, out_features=10, bias=False)
    (2): Linear(in_features=2048, out_features=10, bias=False)
    (3): Linear(in_features=2048, out_features=10, bias=False)
    (4): Linear(in_features=2048, out_features=10, bias=False)
    (5): Linear(in_features=2048, out_features=10, bias=False)
    (6): Linear(in_features=2048, out_features=10, bias=False)
    (7): Linear(in_features=2048, out_features=10, bias=False)
    (8): Linear(in_features=2048, out_features=10, bias=False)
    (9): Linear(in_features=2048, out_features=10, bias=False)
  )
)
[2023-10-04 05:56:46 10splitTasks](iBatchLearn.py 58): INFO #parameter of model:23712832
[2023-10-04 05:56:46 10splitTasks](iBatchLearn.py 167): INFO test split name:0
[2023-10-04 05:56:47 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:56:47 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:56:50 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:56:50 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:56:52 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:56:52 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:56:53 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:56:53 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:56:55 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:56:55 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:56:57 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:56:57 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:56:59 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:56:59 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:01 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:01 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:01 10splitTasks](iBatchLearn.py 167): INFO test split name:1
[2023-10-04 05:57:02 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:02 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:04 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:04 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:05 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:06 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:07 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:07 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:08 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:08 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:10 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:10 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:11 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:11 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:12 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:13 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:13 10splitTasks](iBatchLearn.py 167): INFO test split name:2
[2023-10-04 05:57:14 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:14 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:16 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:16 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:18 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:18 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:19 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:20 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:21 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:21 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:22 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:22 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:24 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:24 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:25 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:25 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:25 10splitTasks](iBatchLearn.py 167): INFO test split name:3
[2023-10-04 05:57:26 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:27 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:28 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:28 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:30 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:30 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:31 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:32 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:33 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:33 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:34 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:35 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:36 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:36 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:37 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:37 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:38 10splitTasks](iBatchLearn.py 167): INFO test split name:4
[2023-10-04 05:57:39 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:39 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:40 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:40 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:42 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:42 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:44 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:44 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:45 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:45 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:47 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:47 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:49 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:50 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:51 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:52 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:52 10splitTasks](iBatchLearn.py 167): INFO test split name:5
[2023-10-04 05:57:53 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:54 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:55 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:55 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:57 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:58 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:57:59 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:57:59 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:58:00 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:58:01 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:58:02 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:58:02 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:58:04 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:58:04 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:58:05 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:58:05 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:58:05 10splitTasks](iBatchLearn.py 167): INFO test split name:6
[2023-10-04 05:58:07 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:58:07 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:58:08 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:58:09 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:58:10 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:58:10 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:58:11 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:58:12 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:58:13 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:58:13 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:58:15 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:58:15 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:58:16 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:58:17 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:58:18 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:58:18 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:58:18 10splitTasks](iBatchLearn.py 167): INFO test split name:7
[2023-10-04 05:58:19 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:58:22 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:58:23 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:58:23 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:58:25 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:58:25 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:58:26 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:58:27 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:58:28 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:58:29 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:58:30 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:58:30 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:58:32 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:58:32 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:58:33 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:58:34 10splitTasks](trainer_miner.py 780): INFO done
--------------------------------Official Evaluation--------------------------------
7 74.2875
=> merge config from utils/user_10splitTasks.yaml
=> merge config from ../official_eva/configs/10splitTasks.yaml
[2023-10-04 05:58:38 10splitTasks](iBatchLearn.py 230): INFO Full config saved to outputs/10splitTasks/trainer_miner-Miner-2023-10-04-05:46:07/config.json
[2023-10-04 05:58:38 10splitTasks](iBatchLearn.py 232): INFO AGENT:
  FIX_BN: false
  FIX_HEAD: true
  MODEL_NAME: resnet50
  MODEL_TYPE: resnet
  NAME: Miner
  REG_COEF: 0.1
  SPARSITY: 0.5
  TYPE: trainer_miner
DATASET:
  BATCHSIZE: 128
  NAME: 10splitTasks
  NUM_CLASSES: 100
  NUM_TASKS: 10
  NUM_WORKERS: 0
  ROOT: input/contest_data/10splitTasks
DOMAIN_INCR: false
GPUID:
- 0
LOGGER_PATH: outputs/10splitTasks/trainer_miner-Miner-2023-10-04-05:46:07
OPT:
  GAMMA: 0.1
  LR: 0.01
  MOMENTUM: 0.9
  NAME: SGD
  SCHEDULE:
  - 80
  SGP_EPS: 0.97
  SGP_EPSINC: 0.0075
  SGP_SCALE: 10
  WEIGHT_DECAY: 0.0
PRINT_FREQ: 10
SEED: 0

[2023-10-04 05:58:38 10splitTasks](iBatchLearn.py 233): INFO {"cfg": "../official_eva/configs/10splitTasks.yaml", "user_cfg": "utils/user_10splitTasks.yaml", "test": true, "task_count": 8, "init_path": "input/init_models/10splitTasks.pth", "ckpt_path": "model_info/10splitTasks/checkpoint-8.pth", "save_ckpt_path": null, "storage_path": "model_info/10splitTasks/storage-8.pth", "save_storage_path": null, "dest_path": "outputs/2023-10-04-05:46:07/prediction_8.pkl", "suffix": "2023-10-04-05:46:07", "distributed": false, "is_main_process": true}
[2023-10-04 05:58:38 10splitTasks](trainer_miner.py 104): INFO => Load model weights: model_info/10splitTasks/checkpoint-8.pth
[2023-10-04 05:58:40 10splitTasks](trainer_miner.py 111): INFO => Load Done
[2023-10-04 05:58:42 10splitTasks](iBatchLearn.py 57): INFO IncreResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (last): ModuleDict(
    (0): Linear(in_features=2048, out_features=10, bias=False)
    (1): Linear(in_features=2048, out_features=10, bias=False)
    (2): Linear(in_features=2048, out_features=10, bias=False)
    (3): Linear(in_features=2048, out_features=10, bias=False)
    (4): Linear(in_features=2048, out_features=10, bias=False)
    (5): Linear(in_features=2048, out_features=10, bias=False)
    (6): Linear(in_features=2048, out_features=10, bias=False)
    (7): Linear(in_features=2048, out_features=10, bias=False)
    (8): Linear(in_features=2048, out_features=10, bias=False)
    (9): Linear(in_features=2048, out_features=10, bias=False)
  )
)
[2023-10-04 05:58:42 10splitTasks](iBatchLearn.py 58): INFO #parameter of model:23712832
[2023-10-04 05:58:42 10splitTasks](iBatchLearn.py 167): INFO test split name:0
[2023-10-04 05:58:43 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:58:43 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:58:47 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:58:47 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:58:49 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:58:49 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:58:50 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:58:50 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:58:51 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:58:52 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:58:53 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:58:53 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:58:54 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:58:54 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:58:55 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:58:56 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:58:56 10splitTasks](iBatchLearn.py 167): INFO test split name:1
[2023-10-04 05:58:57 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:58:57 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:58:58 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:58:58 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:59:00 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:59:00 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:59:01 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:59:01 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:59:03 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:59:03 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:59:04 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:59:04 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:59:06 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:59:06 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:59:07 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:59:07 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:59:07 10splitTasks](iBatchLearn.py 167): INFO test split name:2
[2023-10-04 05:59:09 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:59:09 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:59:10 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:59:10 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:59:12 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:59:12 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:59:13 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:59:13 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:59:15 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:59:15 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:59:16 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:59:17 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:59:18 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:59:18 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:59:20 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:59:20 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:59:20 10splitTasks](iBatchLearn.py 167): INFO test split name:3
[2023-10-04 05:59:22 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:59:22 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:59:24 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:59:24 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:59:27 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:59:27 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:59:29 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:59:29 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:59:31 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:59:31 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:59:33 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:59:34 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:59:36 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:59:36 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:59:37 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:59:38 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:59:38 10splitTasks](iBatchLearn.py 167): INFO test split name:4
[2023-10-04 05:59:40 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:59:40 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:59:42 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:59:42 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:59:44 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:59:44 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:59:45 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:59:46 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:59:47 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:59:47 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:59:48 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:59:49 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:59:50 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:59:50 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:59:52 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:59:52 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:59:52 10splitTasks](iBatchLearn.py 167): INFO test split name:5
[2023-10-04 05:59:53 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:59:54 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:59:55 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:59:55 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:59:57 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:59:57 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 05:59:58 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 05:59:58 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:00:00 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:00:00 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:00:01 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:00:02 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:00:03 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:00:03 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:00:04 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:00:05 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:00:05 10splitTasks](iBatchLearn.py 167): INFO test split name:6
[2023-10-04 06:00:06 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:00:06 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:00:08 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:00:08 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:00:10 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:00:10 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:00:12 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:00:12 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:00:14 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:00:14 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:00:16 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:00:17 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:00:19 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:00:19 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:00:21 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:00:21 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:00:21 10splitTasks](iBatchLearn.py 167): INFO test split name:7
[2023-10-04 06:00:22 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:00:23 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:00:24 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:00:24 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:00:25 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:00:26 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:00:27 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:00:28 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:00:29 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:00:29 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:00:31 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:00:31 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:00:33 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:00:33 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:00:34 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:00:34 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:00:35 10splitTasks](iBatchLearn.py 167): INFO test split name:8
[2023-10-04 06:00:36 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:00:38 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:00:40 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:00:41 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:00:43 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:00:43 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:00:45 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:00:46 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:00:47 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:00:48 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:00:50 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:00:50 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:00:52 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:00:52 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:00:53 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:00:54 10splitTasks](trainer_miner.py 780): INFO done
--------------------------------Official Evaluation--------------------------------
8 74.45555555555555
=> merge config from utils/user_10splitTasks.yaml
=> merge config from ../official_eva/configs/10splitTasks.yaml
[2023-10-04 06:00:59 10splitTasks](iBatchLearn.py 230): INFO Full config saved to outputs/10splitTasks/trainer_miner-Miner-2023-10-04-05:46:07/config.json
[2023-10-04 06:00:59 10splitTasks](iBatchLearn.py 232): INFO AGENT:
  FIX_BN: false
  FIX_HEAD: true
  MODEL_NAME: resnet50
  MODEL_TYPE: resnet
  NAME: Miner
  REG_COEF: 0.1
  SPARSITY: 0.5
  TYPE: trainer_miner
DATASET:
  BATCHSIZE: 128
  NAME: 10splitTasks
  NUM_CLASSES: 100
  NUM_TASKS: 10
  NUM_WORKERS: 0
  ROOT: input/contest_data/10splitTasks
DOMAIN_INCR: false
GPUID:
- 0
LOGGER_PATH: outputs/10splitTasks/trainer_miner-Miner-2023-10-04-05:46:07
OPT:
  GAMMA: 0.1
  LR: 0.01
  MOMENTUM: 0.9
  NAME: SGD
  SCHEDULE:
  - 80
  SGP_EPS: 0.97
  SGP_EPSINC: 0.0075
  SGP_SCALE: 10
  WEIGHT_DECAY: 0.0
PRINT_FREQ: 10
SEED: 0

[2023-10-04 06:00:59 10splitTasks](iBatchLearn.py 233): INFO {"cfg": "../official_eva/configs/10splitTasks.yaml", "user_cfg": "utils/user_10splitTasks.yaml", "test": true, "task_count": 9, "init_path": "input/init_models/10splitTasks.pth", "ckpt_path": "model_info/10splitTasks/checkpoint-9.pth", "save_ckpt_path": null, "storage_path": "model_info/10splitTasks/storage-9.pth", "save_storage_path": null, "dest_path": "outputs/2023-10-04-05:46:07/prediction_9.pkl", "suffix": "2023-10-04-05:46:07", "distributed": false, "is_main_process": true}
[2023-10-04 06:00:59 10splitTasks](trainer_miner.py 104): INFO => Load model weights: model_info/10splitTasks/checkpoint-9.pth
[2023-10-04 06:01:00 10splitTasks](trainer_miner.py 111): INFO => Load Done
[2023-10-04 06:01:02 10splitTasks](iBatchLearn.py 57): INFO IncreResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (last): ModuleDict(
    (0): Linear(in_features=2048, out_features=10, bias=False)
    (1): Linear(in_features=2048, out_features=10, bias=False)
    (2): Linear(in_features=2048, out_features=10, bias=False)
    (3): Linear(in_features=2048, out_features=10, bias=False)
    (4): Linear(in_features=2048, out_features=10, bias=False)
    (5): Linear(in_features=2048, out_features=10, bias=False)
    (6): Linear(in_features=2048, out_features=10, bias=False)
    (7): Linear(in_features=2048, out_features=10, bias=False)
    (8): Linear(in_features=2048, out_features=10, bias=False)
    (9): Linear(in_features=2048, out_features=10, bias=False)
  )
)
[2023-10-04 06:01:02 10splitTasks](iBatchLearn.py 58): INFO #parameter of model:23712832
[2023-10-04 06:01:02 10splitTasks](iBatchLearn.py 167): INFO test split name:0
[2023-10-04 06:01:04 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:01:04 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:01:08 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:01:08 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:01:10 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:01:10 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:01:12 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:01:12 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:01:14 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:01:15 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:01:16 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:01:16 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:01:17 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:01:17 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:01:18 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:01:18 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:01:19 10splitTasks](iBatchLearn.py 167): INFO test split name:1
[2023-10-04 06:01:20 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:01:20 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:01:21 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:01:21 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:01:23 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:01:23 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:01:24 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:01:24 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:01:25 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:01:26 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:01:27 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:01:27 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:01:29 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:01:29 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:01:31 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:01:31 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:01:31 10splitTasks](iBatchLearn.py 167): INFO test split name:2
[2023-10-04 06:01:33 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:01:33 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:01:34 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:01:35 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:01:36 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:01:36 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:01:37 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:01:38 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:01:39 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:01:39 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:01:40 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:01:40 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:01:42 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:01:42 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:01:44 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:01:44 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:01:44 10splitTasks](iBatchLearn.py 167): INFO test split name:3
[2023-10-04 06:01:46 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:01:46 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:01:48 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:01:49 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:01:51 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:01:51 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:01:53 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:01:53 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:01:55 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:01:55 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:01:57 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:01:58 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:02:00 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:02:00 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:02:01 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:02:02 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:02:02 10splitTasks](iBatchLearn.py 167): INFO test split name:4
[2023-10-04 06:02:03 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:02:03 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:02:04 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:02:04 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:02:06 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:02:06 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:02:08 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:02:08 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:02:09 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:02:09 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:02:11 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:02:11 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:02:13 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:02:13 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:02:15 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:02:15 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:02:15 10splitTasks](iBatchLearn.py 167): INFO test split name:5
[2023-10-04 06:02:17 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:02:17 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:02:18 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:02:19 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:02:20 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:02:21 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:02:22 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:02:22 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:02:23 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:02:24 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:02:25 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:02:25 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:02:26 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:02:27 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:02:28 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:02:28 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:02:28 10splitTasks](iBatchLearn.py 167): INFO test split name:6
[2023-10-04 06:02:29 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:02:30 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:02:31 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:02:32 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:02:33 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:02:33 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:02:34 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:02:35 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:02:36 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:02:36 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:02:38 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:02:38 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:02:39 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:02:39 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:02:41 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:02:41 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:02:41 10splitTasks](iBatchLearn.py 167): INFO test split name:7
[2023-10-04 06:02:42 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:02:43 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:02:44 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:02:44 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:02:46 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:02:46 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:02:47 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:02:48 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:02:49 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:02:50 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:02:51 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:02:51 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:02:53 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:02:53 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:02:55 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:02:56 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:02:56 10splitTasks](iBatchLearn.py 167): INFO test split name:8
[2023-10-04 06:02:57 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:02:58 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:03:00 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:03:01 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:03:02 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:03:03 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:03:05 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:03:05 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:03:07 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:03:08 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:03:09 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:03:10 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:03:12 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:03:12 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:03:14 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:03:14 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:03:14 10splitTasks](iBatchLearn.py 167): INFO test split name:9
[2023-10-04 06:03:15 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:03:18 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:03:19 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:03:19 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:03:21 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:03:21 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:03:22 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:03:23 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:03:25 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:03:25 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:03:26 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:03:27 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:03:28 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:03:29 10splitTasks](trainer_miner.py 780): INFO done
[2023-10-04 06:03:30 10splitTasks](trainer_miner.py 776): INFO load storage...
[2023-10-04 06:03:30 10splitTasks](trainer_miner.py 780): INFO done
--------------------------------Official Evaluation--------------------------------
9 74.54999999999998
--------------------------------Final Official Evaluation--------------------------------
75.54419248419971
